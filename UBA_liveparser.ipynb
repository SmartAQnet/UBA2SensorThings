{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import sys\n",
    "import time\n",
    "import requests, json\n",
    "import numpy as np\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "import random\n",
    "import glob\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tounixtime(datetime_input):\n",
    "    return(calendar.timegm(datetime_input.utctimetuple()))\n",
    "\n",
    "def todatetimeformat(utctime):\n",
    "    year=int(utctime[0])*1000 + int(utctime[1])*100 + int(utctime[2])*10 + int(utctime[3])\n",
    "    month=int(utctime[5])*10 + int(utctime[6])\n",
    "    day=int(utctime[8])*10 + int(utctime[9])\n",
    "    hr=int(utctime[11])*10 + int(utctime[12])\n",
    "    minute=int(utctime[14])*10 + int(utctime[15])\n",
    "    second=int(utctime[17])*10 + int(utctime[18])\n",
    "    millisecond=int(utctime[20])*100 + int(utctime[21])*10 + int(utctime[22])   \n",
    "    return(datetime(year,month,day,hr,minute,second,millisecond))\n",
    "\n",
    "def toutcformat(datetime_input):\n",
    "    tstr=str(datetime_input)\n",
    "    year=tstr[0]+tstr[1]+tstr[2]+tstr[3]\n",
    "    month=tstr[5]+tstr[6]\n",
    "    day=tstr[8]+tstr[9]\n",
    "\n",
    "    try:\n",
    "        if type(int(tstr[11]+tstr[12]))==int:\n",
    "            hour=str(tstr[11]+tstr[12])\n",
    "    except:\n",
    "        hour='00'             #no hours given       \n",
    "\n",
    "    try:\n",
    "        if type(int(tstr[14]+tstr[15]))==int:\n",
    "            minute=str(tstr[14]+tstr[15])\n",
    "    except:\n",
    "        minute='00'             #no minutes given\n",
    "\n",
    "    try:\n",
    "        if type(int(tstr[17]+tstr[18]))==int:\n",
    "            second=str(tstr[17]+tstr[18])\n",
    "    except:\n",
    "        second='00'             #no seconds given\n",
    "\n",
    "    try:\n",
    "        if type(int(tstr[20]+tstr[21]+tstr[22]))==int:\n",
    "            millisecond=str(tstr[20]+tstr[21]+tstr[22])\n",
    "    except:\n",
    "        millisecond='000'       #no milliseconds given\n",
    "\n",
    "\n",
    "\n",
    "    utctime=year + '-' + month + '-' + day + 'T' + hour + ':' + minute + ':' + second + '.' + millisecond + 'Z'\n",
    "    return utctime\n",
    "\n",
    "\n",
    "def addminutesutc(utctime,mins):\n",
    "    return(toutcformat(datetime.utcfromtimestamp(tounixtime(todatetimeformat(utctime))+(mins*60))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts numpy types to python types, otherwise json conversion produces an error. call json.dumps(***, cls=MyEncoder)\n",
    "class MyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(MyEncoder, self).default(obj)\n",
    "\n",
    "        \n",
    "\n",
    "# returns strings in the conventional format for iot.ids\n",
    "def idstr(idinput):\n",
    "    return(str(idinput).lower().replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"ä\", \"ae\").replace(\"ö\", \"oe\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\"))\n",
    "\n",
    "\n",
    "# returns the first 7 digits of the sha1 hash of the input string\n",
    "def hashfunc(inputstring, printme):\n",
    "    returnhash= hashlib.sha1(bytes(str(inputstring), 'utf-8')).hexdigest()[0:7]\n",
    "    if printme == True:\n",
    "        print(\"Converting '\" + str(inputstring) + \"' to hash '\" + str(returnhash) +\"'\")\n",
    "    return(returnhash)\n",
    "\n",
    "\n",
    "\n",
    "# returns the full 40 digits of the sha1 hash of the input string\n",
    "def hashfuncfull(inputstring, printme):\n",
    "    returnhash= hashlib.sha1(bytes(str(inputstring), 'utf-8')).hexdigest()\n",
    "    if printme == True:\n",
    "        print(\"Converting '\" + str(inputstring) + \"' to hash '\" + str(returnhash) +\"'\")\n",
    "    return(returnhash)\n",
    "\n",
    "\n",
    "\n",
    "#function that takes a link and gives an array with the link itself and all nextlinks\n",
    "def chainnextlinks(link):\n",
    "    if \"?$\" in link:\n",
    "        querysign=\"&$\"\n",
    "    else:\n",
    "        querysign=\"?$\"\n",
    "        \n",
    "    count = json.loads(requests.get(link + querysign + \"count=True\").text)[\"@iot.count\"] #how many entites in the link\n",
    "    chunks = 1000 #how many you want to fit on one page\n",
    "    baselink = str(link + querysign + 'top=' + str(chunks))\n",
    "    \n",
    "    i=1\n",
    "    links=[baselink]\n",
    "    while count > chunks:\n",
    "        links.append(baselink + '&$skip=' + str(i*chunks))\n",
    "        count = count-chunks\n",
    "        i+=1\n",
    "    return(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = 'https://www.umweltbundesamt.de/js/uaq/data/stations' #get data where from\n",
    "url = \"http://smartaqnet.teco.edu/v1.0\" #post data where to\n",
    "\n",
    "scope='1SMW' #umweltbundesamt website code: 1 hour means\n",
    "scopesec= 60*60 #scope in seconds, needed for interval to tag the next observation\n",
    "feature='PM10'\n",
    "\n",
    "obsproperty_code = \"mcpm10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no data available on datastream saqn:ds:80af8f6\n",
      "no datastream existing for thing Station Augsburg/Haunstetten with observedProperty mcpm10\n"
     ]
    }
   ],
   "source": [
    "# get all existing stations from database\n",
    "# grab value and post to server\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for eachlink in chainnextlinks(url + \"/Things?$filter=properties/operator_url%20eq%20%27lfu.bayern.de%27\"):\n",
    "\n",
    "\n",
    "#alle things von lfu.bayern.de\n",
    "listofthings=json.loads(requests.get(url + \"/Things?$filter=properties/operator_url%20eq%20%27lfu.bayern.de%27\").text)[\"value\"]\n",
    "\n",
    "\n",
    "for thing in listofthings:\n",
    "    \n",
    "    try:\n",
    "        pm10streamid=json.loads(requests.get(url + \"/Things('\" + thing[\"@iot.id\"] + \"')/Datastreams?$filter=ObservedProperty/@iot.id%20eq%20%27saqn:op:\" + obsproperty_code + \"%27&$select=@iot.id\").text)[\"value\"][0][\"@iot.id\"]\n",
    "    except:\n",
    "        print(\"no datastream existing for thing \" + thing[\"name\"] + \" with observedProperty \" + obsproperty_code)\n",
    "        continue\n",
    "    \n",
    "    datastream=json.loads(requests.get(\"http://smartaqnet.teco.edu/v1.0/Datastreams('\" + pm10streamid + \"')\").text)\n",
    "\n",
    "    try:\n",
    "        end_latest_pheno_time = json.loads(requests.get(\"http://smartaqnet.teco.edu/v1.0/Datastreams('\" + pm10streamid + \"')/Observations?$orderby=phenomenontime%20desc&$top=1\").text)[\"value\"][0][\"phenomenonTime\"][-24:]\n",
    "    except: \n",
    "        print(\"no data available on datastream \" + pm10streamid)\n",
    "        continue\n",
    "    \n",
    "    if tounixtime(datetime.utcnow())-tounixtime(todatetimeformat(end_latest_pheno_time)) > scopesec + 10:\n",
    "        begintimeunix=tounixtime(todatetimeformat(end_latest_pheno_time))\n",
    "        endtimeunix=tounixtime(todatetimeformat(end_latest_pheno_time)) + scopesec\n",
    "\n",
    "        #get data from uba\n",
    "        getdatafrom=baseurl + '/measuring?pollutant[]=' + feature + '&scope[]=' + scope + '&station[]=' + thing[\"properties\"][\"station_code\"] + '&group[]=pollutant&range[]=' + str(begintimeunix+10) + ',' + str(endtimeunix+10)\n",
    "        datavalue=json.loads(requests.get(getdatafrom).text)[\"data\"][0][0][0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #get the unhashed datastream id\n",
    "        #thing id           \n",
    "        thing_id_url = thing[\"properties\"][\"operator_url\"]\n",
    "        thing_id_thingname = str(thing[\"name\"])\n",
    "        thing_id_date = str(thing[\"properties\"][\"station_start_date\"])[0:4] + \"-\" + str(thing[\"properties\"][\"station_start_date\"])[4:6]\n",
    "        thing_id_thingnumber = str(thing[\"properties\"][\"station_code\"])\n",
    "\n",
    "        thing_tohash = idstr(thing_id_url + \":\" + thing_id_thingname + \":\" + thing_id_date + \":\" + thing_id_thingnumber)\n",
    "\n",
    "        #Datastream ID\n",
    "        stream_id_url = datastream[\"properties\"][\"operator_url\"] #sollte eigentlich auch in den properties des datastreams stehen\n",
    "        stream_id_sensorname = datastream[\"properties\"][\"sensor_name\"]\n",
    "        stream_id_sensornumber = datastream[\"properties\"][\"sensor_serial_number\"]\n",
    "\n",
    "        stream_tohash = idstr(stream_id_url + \":\" + stream_id_sensorname + \":\" + stream_id_sensornumber)\n",
    "\n",
    "        #ObservedProperty\n",
    "\n",
    "\n",
    "        fullstream_tohash = thing_tohash + \":\" + stream_tohash + \":\" + obsproperty_code\n",
    "\n",
    "        #possible check function if idgeneration was correct\n",
    "#        if \"saqn:ds:\" + hashfunc(fullstream_tohash,False) == pm10streamid:\n",
    "#            print(\"true\")\n",
    "#        else:\n",
    "#            print(\"stream id not correct: \")\n",
    "#            print(\"    \" + pm10streamid + \" != \" + \"saqn:ds:\" + hashfunc(fullstream_tohash,False))\n",
    "#            print(\"    \" + \"tried to hash \" + fullstream_tohash)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #generate observation and push to frost\n",
    "        observation_id_prefix = \"saqn:o:\"\n",
    "        observation_interval = end_latest_pheno_time + \"/\" + \"PT1H\"\n",
    "\n",
    "        observation_tohash = idstr(fullstream_tohash + \":\" + observation_interval) #!!!! fullstream nicht da\n",
    "\n",
    "        generateobsid = observation_id_prefix + hashfuncfull(observation_tohash, False)\n",
    "\n",
    "        observation = {\n",
    "        \"phenomenonTime\" : observation_interval, \n",
    "        \"result\" : datavalue,\n",
    "        \"Datastream\":{\"@iot.id\": str(pm10streamid)},\n",
    "        \"@iot.id\": generateobsid\n",
    "        }\n",
    "        requests.post(url + '/Observations', json.dumps(observation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
