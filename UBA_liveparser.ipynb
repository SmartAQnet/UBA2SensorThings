{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "import pandas as pd\n",
    "import requests, json\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datetime to unixtime\n",
    "def tounixtime(datetime_input):\n",
    "    return(calendar.timegm(datetime_input.utctimetuple()))\n",
    "\n",
    "# returns strings in the conventional format for iot.ids\n",
    "def idstr(idinput):\n",
    "    return(str(idinput).lower().replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"ä\", \"ae\").replace(\"ö\", \"oe\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\"))\n",
    "\n",
    "# returns the first 7 digits of the sha1 hash of the input string\n",
    "def hashfunc(inputstring, printme):\n",
    "    returnhash= hashlib.sha1(bytes(str(inputstring), 'utf-8')).hexdigest()[0:7]\n",
    "    if printme == True:\n",
    "        print(\"Converting '\" + str(inputstring) + \"' to hash '\" + str(returnhash) +\"'\")\n",
    "    return(returnhash)\n",
    "\n",
    "# returns the full 40 digits of the sha1 hash of the input string\n",
    "def hashfuncfull(inputstring, printme):\n",
    "    returnhash= hashlib.sha1(bytes(str(inputstring), 'utf-8')).hexdigest()\n",
    "    if printme == True:\n",
    "        print(\"Converting '\" + str(inputstring) + \"' to hash '\" + str(returnhash) +\"'\")\n",
    "    return(returnhash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = 'https://www.umweltbundesamt.de/js/uaq/data/stations' #get data where from: umweltbundesamt\n",
    "url = \"http://api.smartaq.net/v1.0\" #post data where to: saqn frost server\n",
    "\n",
    "scope='1SMW' #umweltbundesamt website code: 1 hour means\n",
    "scopesec= 60*60 #scope in seconds, needed for interval to tag the next observation\n",
    "\n",
    "feature='PM10' #umweltbundesamt observedProperty code\n",
    "obsproperty_code = \"mcpm10\" #frost server observedProperty code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get all existing UBA stations from frost server \n",
    "- get the latest observation date\n",
    "- get the next observation from UBA server\n",
    "- post to frost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station DBS Augsburg\n",
      "no datastream existing for thing Station DBS Augsburg with observedProperty mcpm10\n",
      "____________________________________________________\n",
      "Station Augsburg/Bourges-Platz\n",
      "Datastream found: saqn:ds:4508dfb\n",
      "latest phenomenon time found: 2019-06-14T13:00:00.000Z\n",
      "2019-06-14T13:00:00.000Z\n",
      "some error\n",
      "____________________________________________________\n",
      "Station Augsburg/LfU\n",
      "Datastream found: saqn:ds:6880098\n",
      "latest phenomenon time found: 2019-06-11T17:00:00.000Z\n",
      "2019-06-11T17:00:00.000Z\n",
      "some error\n",
      "____________________________________________________\n",
      "Station Augsburg/Karlstraße\n",
      "Datastream found: saqn:ds:b88cfcb\n",
      "latest phenomenon time found: 2019-05-28T13:00:00.000Z\n",
      "2019-05-28T13:00:00.000Z\n",
      "some error\n",
      "____________________________________________________\n",
      "Station Augsburg/Königsplatz\n",
      "Datastream found: saqn:ds:80af8f6\n",
      "latest phenomenon time found: 2019-06-14T13:00:00.000Z\n",
      "2019-06-14T13:00:00.000Z\n",
      "some error\n",
      "____________________________________________________\n",
      "Station Augsburg/Haunstetten\n",
      "no datastream existing for thing Station Augsburg/Haunstetten with observedProperty mcpm10\n",
      "____________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#alle things von lfu.bayern.de\n",
    "number_of_things=json.loads(requests.get(url + \"/Things?$filter=properties/operator_url%20eq%20%27lfu.bayern.de%27&$select=@iot.id&$count=True\").text)[\"@iot.count\"]\n",
    "listofthings=json.loads(requests.get(url + \"/Things?$filter=properties/operator_url%20eq%20%27lfu.bayern.de%27&$top=\" + str(number_of_things)).text)[\"value\"]\n",
    "\n",
    "#for each thing...\n",
    "for thing in listofthings:\n",
    "    print(thing[\"name\"])\n",
    "    \n",
    "    #...identify the datastream iot.id corresponding to the observedproperty (pm10)...\n",
    "    try:\n",
    "        pm10streamid=json.loads(requests.get(url + \"/Things('\" + thing[\"@iot.id\"] + \"')/Datastreams?$filter=ObservedProperty/@iot.id%20eq%20%27saqn:op:\" + obsproperty_code + \"%27&$select=@iot.id\").text)[\"value\"][0][\"@iot.id\"]\n",
    "        print(\"Datastream found: \" + str(pm10streamid))\n",
    "    except:\n",
    "        print(\"no datastream existing for thing \" + thing[\"name\"] + \" with observedProperty \" + obsproperty_code)\n",
    "        print(\"____________________________________________________\")\n",
    "        continue\n",
    "    \n",
    "    #... and get the datastream url\n",
    "    datastream=json.loads(requests.get(\"http://smartaqnet.teco.edu/v1.0/Datastreams('\" + pm10streamid + \"')\").text)\n",
    "\n",
    "    \n",
    "    #then find the latest observation\n",
    "    try:\n",
    "        end_latest_pheno_time = json.loads(requests.get(\"http://smartaqnet.teco.edu/v1.0/Datastreams('\" + pm10streamid + \"')/Observations?$orderby=phenomenontime%20desc&$top=1\").text)[\"value\"][0][\"phenomenonTime\"][-24:]\n",
    "        print(\"latest phenomenon time found: \" + str(end_latest_pheno_time))\n",
    "    except: \n",
    "        print(\"no data available on datastream \" + pm10streamid)\n",
    "        print(\"____________________________________________________\")\n",
    "        continue\n",
    "    print(end_latest_pheno_time)\n",
    "    #if a new observation is due, get it\n",
    "    try:\n",
    "        while (pd.datetime.now() - pd.to_datetime(end_latest_pheno_time)).total_seconds() > scopesec + 10:\n",
    "            \n",
    "            begintimeunix=tounixtime(pd.to_datetime(end_latest_pheno_time))\n",
    "            endtimeunix=tounixtime(pd.to_datetime(end_latest_pheno_time)) + scopesec\n",
    "\n",
    "            #get data from uba\n",
    "            getdatafrom=baseurl + '/measuring?pollutant[]=' + feature + '&scope[]=' + scope + '&station[]=' + thing[\"properties\"][\"station_code\"] + '&group[]=pollutant&range[]=' + str(begintimeunix+10) + ',' + str(endtimeunix+10)\n",
    "            datavalue=json.loads(requests.get(getdatafrom).text)[\"data\"][0][0][0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #get the unhashed datastream id\n",
    "            #thing id           \n",
    "            thing_id_url = thing[\"properties\"][\"operator_url\"]\n",
    "            thing_id_thingname = str(thing[\"name\"])\n",
    "            thing_id_date = str(thing[\"properties\"][\"station_start_date\"])[0:4] + \"-\" + str(thing[\"properties\"][\"station_start_date\"])[4:6]\n",
    "            thing_id_thingnumber = str(thing[\"properties\"][\"station_code\"])\n",
    "            thing_tohash = idstr(thing_id_url + \":\" + thing_id_thingname + \":\" + thing_id_date + \":\" + thing_id_thingnumber)\n",
    "\n",
    "            #Datastream ID\n",
    "            stream_id_url = datastream[\"properties\"][\"operator_url\"] #sollte eigentlich auch in den properties des datastreams stehen\n",
    "            stream_id_sensorname = datastream[\"properties\"][\"sensor_name\"]\n",
    "            stream_id_sensornumber = datastream[\"properties\"][\"sensor_serial_number\"]\n",
    "            stream_tohash = idstr(stream_id_url + \":\" + stream_id_sensorname + \":\" + stream_id_sensornumber)\n",
    "\n",
    "            fullstream_tohash = thing_tohash + \":\" + stream_tohash + \":\" + obsproperty_code\n",
    "\n",
    "#             #check function if idgeneration was correct\n",
    "#             if \"saqn:ds:\" + hashfunc(fullstream_tohash,False) == pm10streamid:\n",
    "#                 print(\"hash checksum true\")\n",
    "#             else:\n",
    "#                 print(\"stream id not correct: \")\n",
    "#                 print(\"    \" + pm10streamid + \" != \" + \"saqn:ds:\" + hashfunc(fullstream_tohash,False))\n",
    "#                 print(\"    \" + \"tried to hash \" + fullstream_tohash)\n",
    "\n",
    "\n",
    "\n",
    "            #generate observation and push to frost\n",
    "            observation_id_prefix = \"saqn:o:\"\n",
    "            observation_interval = end_latest_pheno_time + \"/\" + \"PT1H\"\n",
    "            observation_tohash = idstr(fullstream_tohash + \":\" + observation_interval)\n",
    "            generateobsid = observation_id_prefix + hashfuncfull(observation_tohash, False)\n",
    "\n",
    "            observation = {\n",
    "            \"phenomenonTime\" : observation_interval, \n",
    "            \"result\" : datavalue,\n",
    "            \"Datastream\":{\"@iot.id\": str(pm10streamid)},\n",
    "            \"@iot.id\": generateobsid\n",
    "            }\n",
    "            requests.post(url +  \"/Datastreams('\" + pm10streamid + \"')/Observations\", json.dumps(observation))\n",
    "            print(\"Successfully posted an Observation\")\n",
    "            print(\"____________________________________________________\")\n",
    "            \n",
    "                #then find the latest observation\n",
    "            try:\n",
    "                end_latest_pheno_time = json.loads(requests.get(\"http://smartaqnet.teco.edu/v1.0/Datastreams('\" + pm10streamid + \"')/Observations?$orderby=phenomenontime%20desc&$top=1\").text)[\"value\"][0][\"phenomenonTime\"][-24:]\n",
    "                print(\"latest phenomenon time found: \" + str(end_latest_pheno_time))\n",
    "            except: \n",
    "                print(\"no data available on datastream \" + pm10streamid)\n",
    "                print(\"____________________________________________________\")\n",
    "                continue\n",
    "\n",
    "    except:\n",
    "        print(\"some error\")\n",
    "        print(\"____________________________________________________\")\n",
    "        continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
